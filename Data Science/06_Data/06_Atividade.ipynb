{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1UFJ9VIAKVVR"
      },
      "source": [
        "# Redes Neurais: Problemas de Classificacao\n",
        "\n",
        "Autor: Arthur Schneider Figueira"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jw9TYNyKYk_"
      },
      "source": [
        "## Lendo as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxclpGdjKaU3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score,mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMDYv_FqKcSp"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM7Wu8ttKcVg"
      },
      "outputs": [],
      "source": [
        "# Define a semente\n",
        "seed_value = 2023\n",
        "tf.random.set_seed(seed_value)\n",
        "np.random.seed(seed_value)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0cmLb67oKfZx"
      },
      "source": [
        "## Problema Binario: 2 classes\n",
        "\n",
        "Em problemas binários, a função de ativação da última camada deve ser \"sigmoid\", vide:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Adicione a camada de saída\n",
        "model1.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "#O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zFF7ajUVKyTn"
      },
      "source": [
        "Vamos descobrir o gênero do indivíduo, baseado em seus gostos.\n",
        "\n",
        "Variáveis explicativas:\n",
        "1. Cor Favorita;\n",
        "2. Estilo de Musica Favorita;\n",
        "3. Bebida alcoolica favorita;\n",
        "4. Refrigerante favorito;\n",
        "5. Gênero: **é nossa variável resposta**.\n",
        "\n",
        "**Material disponivel em**: [06_gender-classification](https://www.kaggle.com/datasets/hb20007/gender-classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z90gViLTKewv",
        "outputId": "f42fa428-c76a-43d2-a694-ff063d012b7b"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Transformed Data Set - Sheet1.csv')\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HqIq3rBLJn_",
        "outputId": "871c108b-ee85-4a7b-9b5c-2a35ecdd23fb"
      },
      "outputs": [],
      "source": [
        "df.Gender.unique() #Ha duas classes: F (female/feminino) e M (male/masculino)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S1qxL2yLWAf",
        "outputId": "ca752b95-7c86-48a8-acec-9a02034d3c8d"
      },
      "outputs": [],
      "source": [
        "dict(df.Gender.value_counts()) #A base esta balanceada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahT9PmjMLjCP",
        "outputId": "af63dd7d-70f2-4d1d-94cb-d9e9fe5ef936"
      },
      "outputs": [],
      "source": [
        "for col in list(df.columns):\n",
        "  print(col,df[col].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI1EULVyMFgW"
      },
      "outputs": [],
      "source": [
        "#Por serem apenas variaveis categoricas, apliquei dummificacao para a base toda\n",
        "df = pd.get_dummies(df, columns = list(df.columns), dtype=float,drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "erdZRfQwMxme",
        "outputId": "c05f9971-884c-4789-9ac7-fec6234187b7"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3Jj-fxXM0qe"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns = ['Gender_M'])\n",
        "y = df.Gender_M\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=26, random_state=2023,stratify=y)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=10, random_state=2023,stratify=y_test)\n",
        "\n",
        "#Com o parametro stratify, a divisao das bases mantera uma qt equilibrada de M e F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lmJPvJcNkY2",
        "outputId": "2a40bab2-1d08-42e3-f2cd-9cd9b531dbaf"
      },
      "outputs": [],
      "source": [
        "print(f\" Treino {len(X_train)}, Teste {len(X_test)}, Validacao {len(X_val)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PaX2Kf-oN-au"
      },
      "source": [
        "## Modelagem"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BsLvjHDwOEB-"
      },
      "source": [
        "### Parametros da Rede Neural"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e67zOosJOGyG"
      },
      "source": [
        "* Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb_neKcYOAF1"
      },
      "outputs": [],
      "source": [
        "# Incluindo early stopping\n",
        "\n",
        "# Defina o callback EarlyStopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',  # Métrica a ser monitorada\n",
        "    patience=50,          # Número de épocas sem melhoria antes de parar o treinamento\n",
        "    restore_best_weights=True  # Restaura os melhores pesos encontrados durante o treinamento\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-pIjAC3SOKTF"
      },
      "source": [
        "* Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU95vbjmOLs9"
      },
      "outputs": [],
      "source": [
        "# Definindo a função para agendar o learning rate\n",
        "def lr_scheduler(epoch):\n",
        "    if epoch < 50:\n",
        "        return 0.005\n",
        "    elif epoch < 100:\n",
        "        return 0.001\n",
        "    elif epoch < 150:\n",
        "        return 0.0005\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "# Criando o callback para o Learning Rate Scheduler\n",
        "lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# Optei por alterar o learning rate a cada 50 epocas,\n",
        "# pois o early stop vai encerrar o treinamento quando 50 epocas se passarem sem melhorar o modelo."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rOetMIV-ORS1"
      },
      "source": [
        "Lembrete: esses parâmetros (early stopping e learning rate) são utilizados como callbacks:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Treinando o modelo\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=16, callbacks=[lr_scheduler_callback,early_stopping_callback])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tZj2kBbbOVBu"
      },
      "source": [
        "### Otimizador: SGD\n",
        "\n",
        "[Documentacao](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/SGD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opd8hev7OfeV"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model1 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model1.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model1.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model1.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model1.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model1.compile(optimizer=tf.keras.optimizers.SGD(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX436dYpPC11",
        "outputId": "491547f0-f8a2-4956-ff1b-8768e1962e75"
      },
      "outputs": [],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEEheVTWPFqu",
        "outputId": "461c18ce-3b20-47a0-b4b4-3dbeeffd7ae8"
      },
      "outputs": [],
      "source": [
        "history1 = model1.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "362XEhdLP1OF"
      },
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss1 = history1.history['loss']\n",
        "test_loss1 = history1.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "VA1Unfd5P4iN",
        "outputId": "986ea356-f2ce-4d04-8822-671ec06de17e"
      },
      "outputs": [],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss1) + 1)\n",
        "plt.plot(epochs, train_loss1, label='Train Loss')\n",
        "plt.plot(epochs, test_loss1, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kb4yJEoTQMRF"
      },
      "source": [
        "### Otimizador: Adam\n",
        "\n",
        "[Documentacao](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RkyJjBtdQ4Gd",
        "outputId": "a0f81ff1-cd5a-4461-a95f-175a41ae3603"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model2 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model2.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model2.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history2 = model2.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )\n",
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss2 = history2.history['loss']\n",
        "test_loss2 = history2.history['val_loss']\n",
        "\n",
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss2) + 1)\n",
        "plt.plot(epochs, train_loss2, label='Train Loss')\n",
        "plt.plot(epochs, test_loss2, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rGxqhESzQ8fn"
      },
      "source": [
        "### Otimizador RMSprop\n",
        "\n",
        "[Documentacao](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/RMSprop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZWSF96exRYPl",
        "outputId": "13eed23a-d6fd-4c2b-84fa-f61acdab54fc"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model3 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model3.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model3.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model3.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model3.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model3.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history3 = model3.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )\n",
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss3 = history3.history['loss']\n",
        "test_loss3 = history3.history['val_loss']\n",
        "\n",
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss3) + 1)\n",
        "plt.plot(epochs, train_loss3, label='Train Loss')\n",
        "plt.plot(epochs, test_loss3, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yXoLTi_BRb71"
      },
      "source": [
        "### Otimizador: Adagrad\n",
        "\n",
        "[Documentacao](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/Adagrad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zvWQkOKuRlWt",
        "outputId": "a840de90-5977-4f88-d11e-3d3785799ffe"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model4 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model4.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model4.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model4.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model4.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model4.compile(optimizer=tf.keras.optimizers.Adagrad(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history4 = model4.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )\n",
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss4 = history4.history['loss']\n",
        "test_loss4 = history4.history['val_loss']\n",
        "\n",
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss4) + 1)\n",
        "plt.plot(epochs, train_loss4, label='Train Loss')\n",
        "plt.plot(epochs, test_loss4, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t5nj8k4aRohs"
      },
      "source": [
        "### Otimizador: Ada Delta\n",
        "\n",
        "[Documentacao](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/Adadelta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Okb0WuqRq6k",
        "outputId": "ec679d78-d98e-4857-ca10-aad8cfe52b87"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model5 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model5.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model5.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model5.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model5.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model5.compile(optimizer=tf.keras.optimizers.Adadelta(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history5 = model5.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )\n",
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss5 = history5.history['loss']\n",
        "test_loss5 = history5.history['val_loss']\n",
        "\n",
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss5) + 1)\n",
        "plt.plot(epochs, train_loss5, label='Train Loss')\n",
        "plt.plot(epochs, test_loss5, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "smKx05NnRybk"
      },
      "source": [
        "### Otimizador: N Adam\n",
        "\n",
        "[Documentacao](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/Nadam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L3dopUcjR0i0",
        "outputId": "e93c0ea8-a672-482a-96a8-5cbbfa4a8b87"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model6 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model6.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model6.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model6.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model6.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model6.compile(optimizer=tf.keras.optimizers.Nadam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history6 = model6.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )\n",
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss6 = history6.history['loss']\n",
        "test_loss6 = history6.history['val_loss']\n",
        "\n",
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss6) + 1)\n",
        "plt.plot(epochs, train_loss6, label='Train Loss')\n",
        "plt.plot(epochs, test_loss6, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YNwjoC6YTpIk"
      },
      "source": [
        "### Avaliando os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK9Kl3uJSsf3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvtiRZy-UBrO",
        "outputId": "9a07bbc9-c6c1-4df0-ae70-eba6bf352083"
      },
      "outputs": [],
      "source": [
        "[float(x) for x in model1.predict(X_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr0gHE4iUonQ"
      },
      "outputs": [],
      "source": [
        "transforma_bin = lambda x: 1 if x > 0.5 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjYxp6zkUwOr",
        "outputId": "0dcf1633-f903-467f-9eb4-5325eb447f83"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tOvgUiBTv3h",
        "outputId": "74d6a321-42a6-465e-bb81-f89721e58032"
      },
      "outputs": [],
      "source": [
        "print('SGD',accuracy_score(y_val, [transforma_bin(float(x)) for x in model1.predict(X_val)]))\n",
        "print('Adam',accuracy_score(y_val, [transforma_bin(float(x)) for x in model2.predict(X_val)]))\n",
        "print('RMSProp',accuracy_score(y_val, [transforma_bin(float(x)) for x in model3.predict(X_val)]))\n",
        "print('Ada Grad',accuracy_score(y_val, [transforma_bin(float(x)) for x in model4.predict(X_val)]))\n",
        "print('Ada Delta',accuracy_score(y_val, [transforma_bin(float(x)) for x in model5.predict(X_val)]))\n",
        "print('N Adam',accuracy_score(y_val, [transforma_bin(float(x)) for x in model6.predict(X_val)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97aj5_SiU51R",
        "outputId": "d7a3746e-9f2c-44d4-bf3d-9d74bddac9e7"
      },
      "outputs": [],
      "source": [
        "print('Adam: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model2.predict(X_test)]))\n",
        "print('Adam: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model2.predict(X_train)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0v9h9KnWI_K",
        "outputId": "e4b206b9-858a-4c76-d44c-df5d8a2457ca"
      },
      "outputs": [],
      "source": [
        "print('Ada Delta: validacao',accuracy_score(y_val, [transforma_bin(float(x)) for x in model5.predict(X_val)]))\n",
        "print('Ada Delta: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model5.predict(X_test)]))\n",
        "print('Ada Delta: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model5.predict(X_train)]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qp_Ru49dVt6a"
      },
      "source": [
        "### Conclusao\n",
        "* Adam: Por mais que o modelo com o otimizador Adam tenha obtido uma maior acurácia na base de validação (dados novos), percebemos que nas bases de treino e teste, há uma variabilidade alta no resultados. Não é interessante manter um modelo que possa ser **volátil**.\n",
        "\n",
        "* Ada Delta: já o modelo Ada Delta manteve uma acurácia em torno de 70% nas bases de treino e validação - o que já bom. E na base de treino, 75%. É normal a assertividade no treino ser maior que no teste\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cxeKIFbtXiHD"
      },
      "source": [
        "# Atividade\n",
        "\n",
        "1. **(Sem Nota)** Drug 200: problema multiclasse. A base drug200.csv contém dados de saúde paciente dos pacientes e, baseado nisso, recomenda-se tomar um repectivo remédio condito na coluna Drug. Note que há 05 respostas diferentes (problema multiclasse). Portanto, sua última camada será construída como:\n",
        "```\n",
        "# Adicione a camada de saída\n",
        "model6.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
        "#O valor 5 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "```\n",
        "**Lembrete**: transforme cada opção num número de 1 a 5.\n",
        "\n",
        "\n",
        "\n",
        "2. **(Com Nota)** Mushroom: problema binário. A base mushrooms.csv contém dados de **duas** espécies de cogumelos. A base está completamente criptografada e não há um dicionário.\n",
        "\n",
        "**Projeto**:\n",
        "* Testem diferentes arquiteturas para responder a esses problemas;\n",
        "* Testem diferentes otimizadores;\n",
        "* Dependendo da função de perda, adaptem o learning rate.\n",
        "\n",
        "**Entrega:**\n",
        "Realizem a predição da base mushrooms_AC.csv e salvem no drive da respectiva AC. Usem como nome do arquivo NOME_SOBRENOME_NOME2_SOBRENOME2.csv . Utilizem o formato padrão do pandas para exportar o arquivo.\n",
        "\n",
        "A métrica para avaliar será a **acurácia**."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UBAUQe6Pllwy"
      },
      "source": [
        "# Multiclasse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NF8Sod3OVl8d",
        "outputId": "d8a59fc3-7cc4-491d-fdde-b0c2d8c25431"
      },
      "outputs": [],
      "source": [
        "df_drug = pd.read_csv('/content/drive/MyDrive/Data Science/Bases/drug200.csv')\n",
        "df_drug.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wphgplvBXqzc",
        "outputId": "cded83b3-c9fb-45d9-b3ac-88e1b79fabc5"
      },
      "outputs": [],
      "source": [
        "df_drug.Drug.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJsH8dmgjwrt",
        "outputId": "3df9d01c-2066-4d01-938c-66382143e92c"
      },
      "outputs": [],
      "source": [
        "df_drug.Drug.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_-pUvvRj0-M"
      },
      "outputs": [],
      "source": [
        "df_drug.loc[(df_drug.Drug == \"drugA\"), 'drugA'] = 1\n",
        "df_drug.loc[(df_drug.Drug == \"drugB\"), 'drugB'] = 1\n",
        "df_drug.loc[(df_drug.Drug == \"drugC\"), 'drugC'] = 1\n",
        "df_drug.loc[(df_drug.Drug == \"drugX\"), 'drugX'] = 1\n",
        "df_drug.loc[(df_drug.Drug == \"DrugY\"), 'DrugY'] = 1\n",
        "\n",
        "df_drug.loc[(df_drug.drugA != 1), 'drugA'] = 0\n",
        "df_drug.loc[(df_drug.drugB != 1), 'drugB'] = 0\n",
        "df_drug.loc[(df_drug.drugC != 1), 'drugC'] = 0\n",
        "df_drug.loc[(df_drug.drugX != 1), 'drugX'] = 0\n",
        "df_drug.loc[(df_drug.DrugY != 1), 'DrugY'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBQ03ZeakDmH"
      },
      "outputs": [],
      "source": [
        "cats_cols = ['Sex','BP','Cholesterol']\n",
        "df_drug = df_drug.merge(pd.get_dummies(df_drug[cats_cols], prefix=cats_cols), left_index=True, right_index=True, how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "68PhCofQkDok",
        "outputId": "537199a0-0be0-4615-f9ec-0d140d08d269"
      },
      "outputs": [],
      "source": [
        "df_drug.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y3iO_A7m39Z"
      },
      "outputs": [],
      "source": [
        "X = df_drug.drop(columns = ['Sex','BP','Cholesterol','Drug','drugA','drugB','drugC','drugX','DrugY'])\n",
        "y = df_drug[['drugA','drugB','drugC','drugX','DrugY']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=int(len(X)*0.3), random_state=2023,stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpvVZdSgkDrW",
        "outputId": "29d1a0f3-9837-45c4-aa57-34ae49e0e908"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model_drug = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model_drug.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model_drug.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model_drug.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model_drug.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model_drug.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model_drug.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model_drug.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model_drug.add(tf.keras.layers.Dense(5, activation='softmax')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model_drug.compile(optimizer=tf.keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_model_drug = model_drug.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sLUIKI6n-XN",
        "outputId": "7343efd6-3ed0-46ef-a969-311b9e41d4a1"
      },
      "outputs": [],
      "source": [
        "#Predicao\n",
        "model_drug.predict(X_test.values[0:5])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MASUTOUOpxiw"
      },
      "source": [
        "A predição é a chance para cada classe.\n",
        "\n",
        "Considere:\n",
        "```\n",
        "[0.04051146, 0.03295425, 0.0411371 , 0.1267812 , 0.7586159 ]\n",
        "```\n",
        "\n",
        "Isso representa:\n",
        "* Drug A  4.05% de chance;\n",
        "* Drug B  3.29% de chance;\n",
        "* Drug C  4.11% de chance;\n",
        "* Drug X 12.67% de chance;\n",
        "* Drug Y 75.86% de chance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_v8xPH5n-aE",
        "outputId": "702b7560-7b5e-4db0-e381-4c2bdbd1cdec"
      },
      "outputs": [],
      "source": [
        "preditos = model_drug.predict(X_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxSnYuyeqgSh",
        "outputId": "1ea45d6a-7353-42f5-87de-2e03ecb3074b"
      },
      "outputs": [],
      "source": [
        "vetor_da_vez = preditos[0]\n",
        "vetor_da_vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjnU5EbZq5Ak",
        "outputId": "b7c5d9bf-4220-472f-915c-5b14d2ed8085"
      },
      "outputs": [],
      "source": [
        "vetor_posicoes = np.argsort(vetor_da_vez)\n",
        "vetor_posicoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiiCv05ErIuG"
      },
      "outputs": [],
      "source": [
        "DrugA_Rank = []\n",
        "DrugB_Rank = []\n",
        "DrugC_Rank = []\n",
        "DrugX_Rank = []\n",
        "DrugY_Rank = []\n",
        "\n",
        "for vetor_da_vez in preditos:\n",
        "  vetor_posicoes = np.argsort(vetor_da_vez)\n",
        "  DrugA_Rank.append(vetor_posicoes[0])\n",
        "  DrugB_Rank.append(vetor_posicoes[1])\n",
        "  DrugC_Rank.append(vetor_posicoes[2])\n",
        "  DrugX_Rank.append(vetor_posicoes[3])\n",
        "  DrugY_Rank.append(vetor_posicoes[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wJdyOkdRr2Rh",
        "outputId": "1a5530f8-d26f-4431-be0d-26134eb64db6"
      },
      "outputs": [],
      "source": [
        "y_test['DrugA_Rank'] = DrugA_Rank\n",
        "y_test['DrugB_Rank'] = DrugB_Rank\n",
        "y_test['DrugC_Rank'] = DrugC_Rank\n",
        "y_test['DrugX_Rank'] = DrugX_Rank\n",
        "y_test['DrugY_Rank'] = DrugY_Rank\n",
        "y_test.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_iH6sG-GuFfH",
        "outputId": "f8220729-6ff9-4b82-a575-e27378151814"
      },
      "outputs": [],
      "source": [
        "y_test[['DrugA_Rank','DrugB_Rank','DrugC_Rank','DrugX_Rank','DrugY_Rank']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AjHnE5IsLCl",
        "outputId": "b632f1cf-4716-4650-e5a6-742246254b66"
      },
      "outputs": [],
      "source": [
        "#Validando, usando a base de teste\n",
        "\n",
        "rankings_considerados = [4] #Indices vao de 0 a 4\n",
        "for col in ['drugA','drugB','drugC','drugX','DrugY']:\n",
        "  df_aux = y_test.copy()\n",
        "  tradutor = {'drugA':'DrugA_Rank','drugB':'DrugB_Rank','drugC':'DrugC_Rank','drugX':'DrugX_Rank','DrugY':'DrugY_Rank'}\n",
        "  df_aux.loc[(df_aux[tradutor[col]].isin(rankings_considerados)), 'Resposta'] = f'Decidiu por {col}'\n",
        "  df_aux.loc[~(df_aux[tradutor[col]].isin(rankings_considerados)), 'Resposta'] = f'Não Decidiu por {col}'\n",
        "\n",
        "  resumo = df_aux.groupby([col,'Resposta'])['Resposta'].agg(['count'])\n",
        "  print(resumo,'\\n---\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAYQ_kXBvKyW",
        "outputId": "a641fc19-e24e-4a35-d65f-d5fa426e5b59"
      },
      "outputs": [],
      "source": [
        "#Validando, usando a base de teste\n",
        "\n",
        "rankings_considerados = [2,3,4] #Indices vao de 0 a 4\n",
        "for col in ['drugA','drugB','drugC','drugX','DrugY']:\n",
        "  df_aux = y_test.copy()\n",
        "  tradutor = {'drugA':'DrugA_Rank','drugB':'DrugB_Rank','drugC':'DrugC_Rank','drugX':'DrugX_Rank','DrugY':'DrugY_Rank'}\n",
        "  df_aux.loc[(df_aux[tradutor[col]].isin(rankings_considerados)), 'Resposta'] = f'Decidiu por {col}'\n",
        "  df_aux.loc[~(df_aux[tradutor[col]].isin(rankings_considerados)), 'Resposta'] = f'Não Decidiu por {col}'\n",
        "\n",
        "  resumo = df_aux.groupby([col,'Resposta'])['Resposta'].agg(['count'])\n",
        "  print(resumo,'\\n---\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erqu8wt4vaDd",
        "outputId": "7260f812-da69-4748-dbe8-66e0a9cc1709"
      },
      "outputs": [],
      "source": [
        "y_test[['drugA','drugB','drugC','drugX','DrugY']].sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lUk3jDcwukF4"
      },
      "source": [
        "** Conclusão **\n",
        "\n",
        "Nesse exemplo, o modelo não foi capaz de acertar para as drogas A e B. Afinal, todos os casos que deveria recomendar tais drogas, o modelo recomendou outra.\n",
        "\n",
        "Para as drogas Y, ele parece ter indicado corretamente. Entretanto, indicou muitas vezes Y quando o correto seria outra dropa.\n",
        "\n",
        "Ao considerarmos que a droga correta estivesse dentre as 3 com maior probabilidade de indicação, notamos que a assertividade aumenta significativamente e que a droga Y sempre faz parte de uma dessas 3. Isso se justifica, pois a droga Y representa 45% dos dados. Portanto, o modelo acaba priorizando a recomendação da mesma.\n",
        "\n",
        "**Maneiras de tratar:**\n",
        "* Balanceando o banco de dados;\n",
        "* Criando um modelo para determinar se é Dropga Y ou não; um segundo modelo para determinar se é droga X ou não; e um terceiro modelo multiclasse visto que as drogas estariam balanceadas."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1RsVGny4loUU"
      },
      "source": [
        "# Binário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score,mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "cBHfvkAEXtYU",
        "outputId": "45dcf206-af8a-46d3-db8a-b694a1a5ce19"
      },
      "outputs": [],
      "source": [
        "df_mushroom = pd.read_csv('mushrooms.csv')\n",
        "df_mushroom.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val = pd.read_csv('mushrooms_AC.csv')\n",
        "df_val.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val['class'] = df_mushroom['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiIMTbKpXx2y",
        "outputId": "21f1dd46-ee23-42d0-bac8-ba40b1bf7d31"
      },
      "outputs": [],
      "source": [
        "df_mushroom['class'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Ohndrlx-gU",
        "outputId": "eb9327bd-2a7a-4327-d299-4b6e7e676313"
      },
      "outputs": [],
      "source": [
        "len(df_mushroom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mushroom['class'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fklqA0WKzVJC"
      },
      "outputs": [],
      "source": [
        "df_mushroom.loc[(df_mushroom['class'] == \"e\"), 'e'] = 1\n",
        "df_mushroom.loc[(df_mushroom['class'] == \"p\"), 'p'] = 1\n",
        "\n",
        "df_mushroom.loc[(df_mushroom.e != 1), 'e'] = 0\n",
        "df_mushroom.loc[(df_mushroom.p != 1), 'p'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mushroom.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Por serem apenas variaveis categoricas, apliquei dummificacao para a base toda\n",
        "df_mushroom = pd.get_dummies(df_mushroom, columns = list(df_mushroom.columns), dtype=float,drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Por serem apenas variaveis categoricas, apliquei dummificacao para a base toda\n",
        "df_val = pd.get_dummies(df_val, columns = list(df_val.columns), dtype=float,drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "common_columns = [col for col in df_val.columns if col in df_mushroom.columns]\n",
        "df_val = df_val[common_columns]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mushroom.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_mushroom.drop(columns = ['class_p'])\n",
        "y = df_mushroom[['class_p']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=int(len(X)*0.3), random_state=2023,stratify=y)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=10, random_state=2023,stratify=y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\" Treino {len(X_train)}, Teste {len(X_test)}, Validacao {len(df_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Incluindo early stopping\n",
        "\n",
        "# Defina o callback EarlyStopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',  # Métrica a ser monitorada\n",
        "    patience=50,          # Número de épocas sem melhoria antes de parar o treinamento\n",
        "    restore_best_weights=True  # Restaura os melhores pesos encontrados durante o treinamento\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definindo a função para agendar o learning rate\n",
        "def lr_scheduler(epoch):\n",
        "    if epoch < 50:\n",
        "        return 0.005\n",
        "    elif epoch < 100:\n",
        "        return 0.001\n",
        "    elif epoch < 150:\n",
        "        return 0.0005\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "# Criando o callback para o Learning Rate Scheduler\n",
        "lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# Optei por alterar o learning rate a cada 50 epocas,\n",
        "# pois o early stop vai encerrar o treinamento quando 50 epocas se passarem sem melhorar o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model1 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model1.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model1.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model1.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model1.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model1.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model1.compile(optimizer=tf.keras.optimizers.SGD(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=50,start_from_epoch=5,restore_best_weights=True,)\n",
        "\n",
        "history1 = model1.fit(X_train.values, y_train, epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[earlyStopping],\n",
        "                    validation_data=(X_test.values, y_test)\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss1 = history1.history['loss']\n",
        "test_loss1 = history1.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss1) + 1)\n",
        "plt.plot(epochs, train_loss1, label='Train Loss')\n",
        "plt.plot(epochs, test_loss1, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model2 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model2.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model2.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history2 = model2.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss2 = history2.history['loss']\n",
        "test_loss2 = history2.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss2) + 1)\n",
        "plt.plot(epochs, train_loss2, label='Train Loss')\n",
        "plt.plot(epochs, test_loss2, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model3 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model3.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model3.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model3.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model3.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model3.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history3 = model3.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss3 = history3.history['loss']\n",
        "test_loss3 = history3.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss3) + 1)\n",
        "plt.plot(epochs, train_loss3, label='Train Loss')\n",
        "plt.plot(epochs, test_loss3, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model4 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model4.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model4.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model4.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model4.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model4.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model4.compile(optimizer=tf.keras.optimizers.Adagrad(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history4 = model4.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss4 = history4.history['loss']\n",
        "test_loss4 = history4.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss4) + 1)\n",
        "plt.plot(epochs, train_loss4, label='Train Loss')\n",
        "plt.plot(epochs, test_loss4, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ada delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model5 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model5.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model5.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model5.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model5.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model5.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model5.compile(optimizer=tf.keras.optimizers.Adadelta(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history5 = model5.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss5 = history5.history['loss']\n",
        "test_loss5 = history5.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss5) + 1)\n",
        "plt.plot(epochs, train_loss5, label='Train Loss')\n",
        "plt.plot(epochs, test_loss5, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# N Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model6 = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model6.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model6.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model6.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model6.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model6.add(tf.keras.layers.Dense(1, activation='sigmoid')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model6.compile(optimizer=tf.keras.optimizers.Nadam(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history6 = model6.fit(X_train.values, np.array(y_train), epochs=200, batch_size=int(0.25*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss6 = history6.history['loss']\n",
        "test_loss6 = history6.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss6) + 1)\n",
        "plt.plot(epochs, train_loss6, label='Train Loss')\n",
        "plt.plot(epochs, test_loss6, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[float(x) for x in model1.predict(X_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transforma_bin = lambda x: 1 if x > 0.5 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('SGD',accuracy_score(y_val, [transforma_bin(float(x)) for x in model1.predict(X_val)]))\n",
        "print('Adam',accuracy_score(y_val, [transforma_bin(float(x)) for x in model2.predict(X_val)]))\n",
        "print('RMSProp',accuracy_score(y_val, [transforma_bin(float(x)) for x in model3.predict(X_val)]))\n",
        "print('Ada Grad',accuracy_score(y_val, [transforma_bin(float(x)) for x in model4.predict(X_val)]))\n",
        "print('Ada Delta',accuracy_score(y_val, [transforma_bin(float(x)) for x in model5.predict(X_val)]))\n",
        "print('N Adam',accuracy_score(y_val, [transforma_bin(float(x)) for x in model6.predict(X_val)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('SGD: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model1.predict(X_test)]))\n",
        "print('SGD: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model1.predict(X_train)]))\n",
        "print('SGD: validacao',accuracy_score(y_val, [transforma_bin(float(x)) for x in model1.predict(X_val)]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Adam: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model2.predict(X_test)]))\n",
        "print('Adam: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model2.predict(X_train)]))\n",
        "print('Adam: validacao',accuracy_score(y_val, [transforma_bin(float(x)) for x in model2.predict(X_val)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('RMSProp: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model3.predict(X_test)]))\n",
        "print('RMSProp: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model3.predict(X_train)]))\n",
        "print('RMSprop: validacao',accuracy_score(y_val, [transforma_bin(float(x)) for x in model3.predict(X_val)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Ada Grad: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model4.predict(X_test)]))\n",
        "print('Ada Grad: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model4.predict(X_train)]))\n",
        "print('Ada Grad',accuracy_score(y_val, [transforma_bin(float(x)) for x in model4.predict(X_val)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Ada Delta: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model5.predict(X_test)]))\n",
        "print('Ada Delta: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model5.predict(X_train)]))\n",
        "print('Ada Delta: validacao',accuracy_score(y_val, [transforma_bin(float(x)) for x in model5.predict(X_val)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('N Adam: teste',accuracy_score(y_test, [transforma_bin(float(x)) for x in model6.predict(X_test)]))\n",
        "print('N Adam: treino',accuracy_score(y_train, [transforma_bin(float(x)) for x in model6.predict(X_train)]))\n",
        "print('N Adam: validacao',accuracy_score(y_val, [transforma_bin(float(x)) for x in model6.predict(X_val)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mushroom.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_mushroom.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_not_in_val = [col for col in df_mushroom.columns if col not in df_val.columns]\n",
        "print(columns_not_in_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_not_in_val = [col for col in df_mushroom.columns if col not in df_val.columns]\n",
        "\n",
        "# Remove as colunas ausentes de df_mushroom em df_val\n",
        "df_mushroom.drop(columns=columns_not_in_val, inplace=True)\n",
        "\n",
        "# Agora df_mushroom e df_val têm as mesmas colunas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_mushroom.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identifique as colunas ausentes em df_val, mas presentes em df_mushroom\n",
        "extra_columns_in_val = set(df_mushroom.columns) - set(df_val.columns)\n",
        "\n",
        "# Remova essas colunas de df_mushroom\n",
        "df_mushroom = df_mushroom.drop(columns=list(extra_columns_in_val))\n",
        "\n",
        "# Reordene as colunas de df_val para que correspondam à ordem em df_mushroom\n",
        "df_val = df_val[df_mushroom.columns]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mushroom.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
